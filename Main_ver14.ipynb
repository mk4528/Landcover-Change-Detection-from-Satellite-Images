{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CSTJsGjS3iX"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1amCHiGSQ0s"
      },
      "outputs": [],
      "source": [
        "# For U-Net\n",
        "!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abXz7NU8xvCj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import sys\n",
        "import gc\n",
        "import rasterio\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from osgeo import gdal, ogr, osr\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Pu-4m92HYH"
      },
      "outputs": [],
      "source": [
        "### For Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXw_H-r__fRF"
      },
      "outputs": [],
      "source": [
        "SEED_NUM = 0\n",
        "NUM_SPLITS = 5 # Train in 1 epoch using image in (bach_size * NUM_SPLITS ** 2, 4, 3880 / NUM_SPLITS, 3880 / NUM_SPLITS)\n",
        "SPL_WH = int(3880 / NUM_SPLITS)\n",
        "\n",
        "ROOT_PATH = '/content/'\n",
        "MAIN_DIRECTORY = ROOT_PATH + 'drive/MyDrive/Columbia/JPMC3-2' # Set the directory to save and load files\n",
        "df = pd.read_csv(MAIN_DIRECTORY + '/training_set_naip_nlcd_both.csv')  # Save training_set_naip_nlcd_both.csv before running\n",
        "\n",
        "# File path of the exported label (/catalog/labels/data/XXXX_hr_label-YYYY.geojson) from GroundWork,\n",
        "# with XXXX of ID and YYYY of year like 3716_hr_label-2013.geojson\n",
        "TEST_HR_DIRECTORY = MAIN_DIRECTORY + '/test_hr_geojson/'\n",
        "TEST_ID_LIST = ['1950', '3137', '3313', '3716']\n",
        "\n",
        "NUM_WE_SELECT = 512 # Roughly 60M * NUM_WE_SELECT size is required!! Max num = 4500, Max size = 270GB\n",
        "EPOCH = 10\n",
        "BATCH = 4\n",
        "\n",
        "RENEW_TRAIN_DATASET_FLAG = True\n",
        "RENEW_TEST_DATASET_FLAG = True\n",
        "CODALAB_NAIP_DOWNLOAD_FLAG = True\n",
        "\n",
        "# Set some, like ['FCN1l', 'FCN5l'], (or one, like ['FCN1l'], if running single model)\n",
        "# out of 'FCN1l', 'FCN5l', 'U-NET18', and 'U-NET50'\n",
        "MODEL_LIST = ['U-NET18', 'U-NET50'] # Do not change this list when training and evaluating ensemble models\n",
        "OUTPUT_FILES_NAME = 'U-NET18_U-NET50'\n",
        "\n",
        "# Set True when training ensemble models\n",
        "TRAIN_ENSEMBLE_FLAG = True\n",
        "\n",
        "# Set ID (0, 1, 2, 3, ...) of the ensemble model when training ensemble model with new initial network parameters and\n",
        "# new random set of training dataset in mini-batch training.\n",
        "ENSEMBLE_ID = 0\n",
        "\n",
        "# Set True when evaluating ensemble model after training all ensemble models\n",
        "EVALUATE_ENSEMBLE_FLAG = False\n",
        "NUM_ENSEMBLE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkix6nedsO7H"
      },
      "outputs": [],
      "source": [
        "if TRAIN_ENSEMBLE_FLAG:\n",
        "    flag_check = (not TRAIN_ENSEMBLE_FLAG) or (not EVALUATE_ENSEMBLE_FLAG)\n",
        "    if not flag_check:\n",
        "        print('Do not train and evaluate at the same time. Evaluate after training ensemble models.')\n",
        "        assert flag_check\n",
        "    SEED_NUM = SEED_NUM + ENSEMBLE_ID\n",
        "    OUTPUT_FILES_NAME = OUTPUT_FILES_NAME + '_ENS_' + str(ENSEMBLE_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwU8_Y1411uY"
      },
      "outputs": [],
      "source": [
        "# Not need to change these path unless you want to\n",
        "\n",
        "# Directory to save numpy data and png files made from high reolution label geojson files\n",
        "TEST_HR_NP_PNG_PATH = MAIN_DIRECTORY + '/data/test_hr_np_png/'\n",
        "\n",
        "TRAIN_NAIP_DIRECTORY = MAIN_DIRECTORY + '/data/train_image/'\n",
        "TRAIN_NLCD_DIRECTORY = MAIN_DIRECTORY + '/data/train_label/'\n",
        "CHAIN_OUTPUT_DIRECTORY = MAIN_DIRECTORY + '/data/chain_label/'\n",
        "TEST_NAIP_DIRECTORY = MAIN_DIRECTORY + '/data/test_image/'\n",
        "TEST_NLCD_DIRECTORY = MAIN_DIRECTORY + '/data/test_label/'\n",
        "TRAINED_OBJECT_DIRECTORY = MAIN_DIRECTORY + '/trained_objects/'\n",
        "OUTPUT_IMAGE_DIRECTORY = MAIN_DIRECTORY + '/output_images/'\n",
        "CODALAB_NAIP_DIRECTORY = MAIN_DIRECTORY + '/data/codalab_test_image/'\n",
        "CODALAB_PRED_DIRECTORY = ROOT_PATH + 'codalab_test_prediction/'\n",
        "CODALAB_SUBMISSION_DIRECTORY = ROOT_PATH + 'codalab_test_submission/'\n",
        "CODALAB_SUBMISSION_ZIP_DIRECTORY = MAIN_DIRECTORY + '/codalab_submission/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgwcHEEQo_xo"
      },
      "outputs": [],
      "source": [
        "NLCD_CLASSES = [0, 11, 12, 21, 22, 23, 24, 31, 41, 42, 43, 52, 71, 81, 82, 90, 95] # 16 classes + 1 nodata class (\"0\").\n",
        "NUM_DFC2021_CLASS = 5 # Output classes (0: Water, 1: Tree Canopy, 2: Low Vegetation , 3: Impervious, 4: None)\n",
        "NLCD_IDX_TO_REDUCED_LC_MAP = np.array([\n",
        "    4,#  0 No data 0\n",
        "    0,#  1 Open Water\n",
        "    4,#  2 Ice/Snow\n",
        "    2,#  3 Developed Open Space\n",
        "    3,#  4 Developed Low Intensity\n",
        "    3,#  5 Developed Medium Intensity\n",
        "    3,#  6 Developed High Intensity\n",
        "    3,#  7 Barren Land\n",
        "    1,#  8 Deciduous Forest\n",
        "    1,#  9 Evergreen Forest\n",
        "    1,# 10 Mixed Forest\n",
        "    1,# 11 Shrub/Scrub\n",
        "    2,# 12 Grassland/Herbaceous\n",
        "    2,# 13 Pasture/Hay\n",
        "    2,# 14 Cultivated Crops\n",
        "    1,# 15 Woody Wetlands\n",
        "    1,# 16 Emergent Herbaceious Wetlands\n",
        "])\n",
        "\n",
        "# set rescaling weights given to each class in loss function based on the distribution of target classes,\n",
        "# (W, TC, LV, I) = (0.09, 0.453, 0.376, 0.081), and considering the percentage of None as 1/5 = 0.2\n",
        "LOSS_WEIGHT = 1 / np.array([0.09, 0.453, 0.376, 0.081, 0.2]) / 5\n",
        "MEAN_STD = {'2013': {'mean': [115.33700726, 128.85735351, 120.71228705, 157.53005651],\n",
        "                     'std': [40.49209837, 39.70903589, 28.3181713, 67.99788979]},\n",
        "            '2017': {'mean': [72.44318449, 86.37860107, 76.32562186, 130.50011478],\n",
        "                     'std': [42.01297086, 35.15398457, 29.21830352, 59.32915633]}} # Pre-calculated by all training naip images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPgt7cup7yyi"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fq6IkCdP-Wb"
      },
      "outputs": [],
      "source": [
        "def store_np_and_png(nlcd_path, hr_label_path, output_path, image_id_year):\n",
        "    \"\"\"\n",
        "    Please export the high-res label(s) from GroundWork using \"export data\" tab.\n",
        "    You only need to select the check-box of tile layer for the image options.\n",
        "    Then you can DL catalog.zip from GroundWork.\n",
        "    In this function, you will import the geojason file where high-res label data are stored.\n",
        "    We also import the original NLCD low-res label, but this is only to get the size of the *label*.\n",
        "    \n",
        "    Note that we need to at least label the upper left and the lower right corner of the original NAIP image,\n",
        "    because the largest and smallest coordinates are required to accurately transform to a png image file.\n",
        "\n",
        "    Input:\n",
        "        nlcd_path: File path of the downloaded NLCD image\n",
        "        hr_label_path: File path of the exported label data (/catalog/labels/data/xxx.geojson) from GroundWork\n",
        "        output_path: Folder path to save outputs\n",
        "        image_id_year: 'Image_file_ID + \"_\" + year' to name outputs\n",
        "\n",
        "    Output:\n",
        "        image_gray_np: np.array of high-resolution label in gray scale\n",
        "        image: rgb image with three channels (light blue: Water, dark green: Tree Canopy, light green: Low Vegetation, red: Impervious).\n",
        "               Use this to visually check the curated high-res label\n",
        "        image_gray: gray-scale image with only one channel (0: Water, 1: Tree Canopy, 2: Low Vegetation, 3: Impervious).\n",
        "                Note that these are the same with Codalab https://codalab.lisn.upsaclay.fr/competitions/7908). Use this to test our models\n",
        "    \"\"\"\n",
        "    from PIL import Image, ImageDraw\n",
        "    import json\n",
        "\n",
        "    def calc_map_LonLat(nlcd_path):\n",
        "        def intermidiate_calc(extracted_xy):\n",
        "            ms  = re.search('\\..*\"',  extracted_xy).group()[1:-1]\n",
        "            sec = re.search('\\'.*\\.', extracted_xy).group()[1:-1]\n",
        "            min = re.search('d.*\\'',  extracted_xy).group()[1:-1]\n",
        "            deg = re.search('.*d',    extracted_xy).group()[0:-1]\n",
        "            return(int(deg) + int(min) / 60 + int(sec) / 3600 + int(ms) / 3600000)\n",
        "        \n",
        "        def calc_mapXY(extracted_UL_LR):\n",
        "            mapX = - intermidiate_calc(re.search('\\).*W', extracted_UL_LR).group()[3:-1])\n",
        "            mapY =   intermidiate_calc(re.search('W,.*N', extracted_UL_LR).group()[2:-1])\n",
        "            return(mapX, mapY)\n",
        "\n",
        "        txt = gdal.Info(nlcd_path)\n",
        "        extracted_UL = re.search('Upper Left.*\\nLower Left', txt).group()\n",
        "        extracted_LR = re.search('Lower Right.*\\nCenter', txt).group()\n",
        "        _mapXmin_, _mapYmax_ = calc_mapXY(extracted_UL)\n",
        "        _mapXmax_, _mapYmin_ = calc_mapXY(extracted_LR)\n",
        "\n",
        "        return(_mapXmin_, _mapYmax_, _mapXmax_, _mapYmin_)\n",
        "\n",
        "    def make_save_image_np(nlcd_path, hr_label_path, output_path, image_id_year):\n",
        "        # Open the data source and read in the extent\n",
        "        data_source = ogr.Open(hr_label_path)\n",
        "        if data_source is None:\n",
        "            print ('Could not open file')\n",
        "            sys.exit(1)\n",
        "\n",
        "        mapXmin, mapXmax, mapYmin, mapYmax = data_source.GetLayer().GetExtent()\n",
        "        _mapXmin_, _mapYmax_, _mapXmax_, _mapYmin_ = calc_map_LonLat(nlcd_path)\n",
        "\n",
        "        print(\"X and Y-coordinates are longitude and latitude respectively\",\n",
        "              \"\\nmapXmin: \", mapXmin, \"\\nmapXmax: \", mapXmax, \"\\nmapYmin: \", mapYmin, \"\\nmapYmax: \", mapYmax,\n",
        "              \"\\n\\nfrom corresponding NLCD\",\n",
        "              \"\\nmapXmin: \", _mapXmin_, \"\\nmapXmax: \", _mapXmax_, \"\\nmapYmin: \", _mapYmin_, \"\\nmapYmax: \", _mapYmax_,\n",
        "              \"\\nNote that it seems to be better to use the one from the exported high-res label from GroundWork\",\n",
        "              \"\\n\\nW:\", mapXmax - mapXmin, \"\\nH:\", mapYmax - mapYmin)\n",
        "\n",
        "        # Define pixel_size \n",
        "        # pixel_size = 0.5 # meters are one pixel\n",
        "        # Create the target data source\n",
        "        gdal_nlcd = gdal.Open(nlcd_path, gdal.GA_ReadOnly)\n",
        "        target_Width = gdal_nlcd.RasterXSize\n",
        "        target_Height = gdal_nlcd.RasterYSize\n",
        "\n",
        "        pixel_size_x = abs(mapXmax - mapXmin) / target_Width\n",
        "        pixel_size_y = abs(mapYmax - mapYmin) / target_Height\n",
        "        print(\"pixel_size_x:\", pixel_size_x, \"\\npixel_size_y:\", pixel_size_y)\n",
        "\n",
        "        image_TC = Image.new('RGB', (target_Width, target_Height))\n",
        "        image_gray_TC = Image.new('L', (target_Width, target_Height))\n",
        "        image_Im = Image.new('RGB', (target_Width, target_Height))\n",
        "        image_gray_Im = Image.new('L', (target_Width, target_Height))\n",
        "        image_W = Image.new('RGB', (target_Width, target_Height))\n",
        "        image_gray_W = Image.new('L', (target_Width, target_Height))\n",
        "        image_LV = Image.new('RGB', (target_Width, target_Height))\n",
        "        image_gray_LV = Image.new('L', (target_Width, target_Height))\n",
        "\n",
        "        draw_TC = ImageDraw.Draw(image_TC)\n",
        "        draw_gray_TC = ImageDraw.Draw(image_gray_TC)\n",
        "        draw_Im = ImageDraw.Draw(image_Im)\n",
        "        draw_gray_Im = ImageDraw.Draw(image_gray_Im)\n",
        "        draw_W = ImageDraw.Draw(image_W)\n",
        "        draw_gray_W = ImageDraw.Draw(image_gray_W)\n",
        "        draw_LV = ImageDraw.Draw(image_LV)\n",
        "        draw_gray_LV = ImageDraw.Draw(image_gray_LV)\n",
        "\n",
        "        # Loop through the features in the layer\n",
        "        json_source = json.load(open(hr_label_path))\n",
        "        for ftr in json_source.get('features'):\n",
        "            att = ftr.get('properties')['default']\n",
        "\n",
        "            for multipolygon in ftr['geometry']['coordinates']: #4D coordata\n",
        "                for ply in multipolygon:\n",
        "                    ply = np.array(ply)\n",
        "                    loc = np.argmax(ply[:, 0])\n",
        "                    v1 = ply[loc] - ply[loc - 1]\n",
        "                    v2 = ply[loc + 1] - ply[loc - 1]\n",
        "\n",
        "                    ply = (ply - [mapXmin, mapYmax]) * [1, -1] / [pixel_size_x, pixel_size_y]\n",
        "                    ply = [(a[0], a[1]) for a in ply.tolist()]\n",
        "\n",
        "                    if v1[0] * v2[1] - v1[1] * v2[0] >= 0:\n",
        "                        if(att == 'Tree Canopy'):\n",
        "                            color = (0, 128, 0); color2 = 1 #dark green\n",
        "                            draw_TC.polygon(ply, fill = color, outline = None)\n",
        "                            draw_gray_TC.polygon(ply, fill = color2, outline = None)\n",
        "                        elif(att == 'Impervious'):\n",
        "                            color = (255, 0, 0); color2 = 3 #red\n",
        "                            draw_Im.polygon(ply, fill = color, outline = None)\n",
        "                            draw_gray_Im.polygon(ply, fill = color2, outline = None)\n",
        "                        elif(att == 'Water'):\n",
        "                            color = (0, 225, 225); color2 = 0 #light blue\n",
        "                            draw_W.polygon(ply, fill = color, outline = None)\n",
        "                            draw_gray_W.polygon(ply, fill = color2, outline = None)\n",
        "                        elif(att == 'Low Vegetation'):\n",
        "                            color = (0, 255, 0); color2 = 2 #light green\n",
        "                            draw_LV.polygon(ply, fill = color, outline = None)\n",
        "                            draw_gray_LV.polygon(ply, fill = color2, outline = None)\n",
        "                        else: raise ValueError('Wrong target class!')\n",
        "                    else:\n",
        "                        if(att == 'Tree Canopy'):\n",
        "                            draw_TC.polygon(ply, fill = (0, 0, 0), outline = None)\n",
        "                            draw_gray_TC.polygon(ply, fill = 0, outline = None)\n",
        "                        elif(att == 'Impervious'):\n",
        "                            draw_Im.polygon(ply, fill = (0, 0, 0), outline = None)\n",
        "                            draw_gray_Im.polygon(ply, fill = 0, outline = None)\n",
        "                        elif(att == 'Water'):\n",
        "                            draw_W.polygon(ply, fill = (0, 0, 0), outline = None)\n",
        "                            draw_gray_W.polygon(ply, fill = 0, outline = None)\n",
        "                        elif(att == 'Low Vegetation'):\n",
        "                            draw_LV.polygon(ply, fill = (0, 0, 0), outline = None)\n",
        "                            draw_gray_LV.polygon(ply, fill = 0, outline = None)\n",
        "                        else: raise ValueError('Wrong target class!')\n",
        "\n",
        "        image_TC_np = np.array(image_TC)\n",
        "        image_Im_np = np.array(image_Im)\n",
        "        image_W_np = np.array(image_W)\n",
        "        image_LV_np = np.array(image_LV)\n",
        "        image_gray_TC_np = np.array(image_gray_TC)\n",
        "        image_gray_Im_np = np.array(image_gray_Im)\n",
        "        image_gray_W_np = np.array(image_gray_W)\n",
        "        image_gray_LV_np = np.array(image_gray_LV)\n",
        "\n",
        "        # prioritize in order of Im ->  LV ->  TC ->  W\n",
        "        image_LV_np[np.sum(image_Im_np, axis = -1) > 0, :] = 0\n",
        "        image_TC_np[np.sum(image_Im_np, axis = -1) > 0, :] = 0\n",
        "        image_W_np[np.sum(image_Im_np, axis = -1) > 0, :] = 0\n",
        "        image_gray_LV_np[image_gray_Im_np > 0] = 0\n",
        "        image_gray_TC_np[image_gray_Im_np > 0] = 0\n",
        "        image_gray_W_np[image_gray_Im_np > 0] = 0\n",
        "\n",
        "        image_TC_np[np.sum(image_LV_np, axis = -1) > 0, :] = 0\n",
        "        image_W_np[np.sum(image_LV_np, axis = -1) > 0, :] = 0\n",
        "        image_gray_TC_np[image_gray_LV_np > 0] = 0\n",
        "        image_gray_W_np[image_gray_LV_np > 0] = 0\n",
        "\n",
        "        image_W_np[np.sum(image_TC_np, axis = -1) > 0, :] = 0\n",
        "        image_gray_W_np[image_gray_TC_np > 0] = 0\n",
        "\n",
        "        image_np = image_TC_np + image_Im_np + image_W_np + image_LV_np\n",
        "        image_gray_np = image_gray_TC_np + image_gray_Im_np + image_gray_W_np + image_gray_LV_np\n",
        "        np.save(output_path + \"image_rgb-\" + image_id_year, image_np)\n",
        "        np.save(output_path + \"image_gray-\" + image_id_year, image_gray_np)\n",
        "\n",
        "        return(image_np, image_gray_np)\n",
        "\n",
        "    image_np, image_gray_np = make_save_image_np(nlcd_path, hr_label_path, output_path, image_id_year)\n",
        "    image = Image.fromarray(image_np)\n",
        "    image_gray = Image.fromarray(image_gray_np)\n",
        "\n",
        "    print(f'\\nsize of image: {image.size}', f'\\nsize of image_gray: {image_gray.size}',\n",
        "          f'\\nsize of image -- rbg: {image_np.shape} as numpy array',\n",
        "          f'\\nsize of image_gray -- gray-scale: {image_gray_np.shape} as numpy array')\n",
        "    print('\\n---Distribution-------------------',\n",
        "          '\\n0: Water', '\\n1: Tree Canopy', '\\n2: Low Vegetation', '\\n3: Impervious\\n\\n',\n",
        "          pd.Series(image_gray_np.flatten()).value_counts())\n",
        "\n",
        "    gdal_nlcd = gdal.Open(nlcd_path, gdal.GA_ReadOnly)\n",
        "    nlcd_np = np.array([gdal_nlcd.GetRasterBand(i + 1).ReadAsArray() for i in range(gdal_nlcd.RasterCount)])\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
        "    ax[0].imshow(image)\n",
        "    ax[0].set_title(\"high-res label (rgb)\")\n",
        "    ax[1].imshow(image_gray, cmap = 'gray')\n",
        "    ax[1].set_title(\"high-res label (gray-scale)\")\n",
        "    ax[2].imshow(nlcd_np[0], cmap = 'gray')\n",
        "    ax[2].set_title(\"NLCD low-res label (gray-scale)\")\n",
        "    plt.show()\n",
        "\n",
        "    image.save(output_path + \"image_rgb-\" + image_id_year + '.png')\n",
        "    image_gray.save(output_path + \"image_gray-\" + image_id_year + '.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb2d9fyWyUO2"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "def download_file(save_path, save_file_name, url):\n",
        "    os.makedirs(save_path, exist_ok = True)\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as web_file, open(save_path + save_file_name, 'wb') as local_file:\n",
        "            local_file.write(web_file.read())\n",
        "    except urllib.error.URLError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v8rNgp40r6U"
      },
      "outputs": [],
      "source": [
        "if RENEW_TEST_DATASET_FLAG:\n",
        "    file_names = os.listdir(TEST_HR_DIRECTORY)\n",
        "    shutil.rmtree(TEST_NAIP_DIRECTORY, ignore_errors = True)\n",
        "    shutil.rmtree(TEST_NLCD_DIRECTORY, ignore_errors = True)\n",
        "    shutil.rmtree(TEST_HR_NP_PNG_PATH, ignore_errors = True)\n",
        "    os.makedirs(TEST_HR_NP_PNG_PATH, exist_ok = True)\n",
        "\n",
        "    for fn in sorted([file for file in file_names if file.endswith('.geojson')]):\n",
        "        print(fn)\n",
        "        id = fn[:4]\n",
        "        year = fn[-12:-8]\n",
        "\n",
        "        naip_file_name = id + '_naip-' + year + '.tif'\n",
        "        download_file(save_path = TEST_NAIP_DIRECTORY, save_file_name = naip_file_name,\n",
        "                      url = 'https://dfc2021.blob.core.windows.net/competition-data/naip-' + year + '/' + naip_file_name)\n",
        "\n",
        "        if year == '2017':\n",
        "            nlcd_year = '2016'\n",
        "        else:\n",
        "            nlcd_year = year\n",
        "        nlcd_file_name = id + '_nlcd-' + nlcd_year + '.tif'\n",
        "        download_file(save_path = TEST_NLCD_DIRECTORY, save_file_name = nlcd_file_name,\n",
        "                      url = 'https://dfc2021.blob.core.windows.net/competition-data/nlcd-' + nlcd_year + '/' + nlcd_file_name)\n",
        "        \n",
        "        store_np_and_png(nlcd_path = TEST_NLCD_DIRECTORY + nlcd_file_name, hr_label_path = TEST_HR_DIRECTORY + fn,\n",
        "                         output_path = TEST_HR_NP_PNG_PATH, image_id_year = id + '_' + year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VlJOsWnGH1W"
      },
      "outputs": [],
      "source": [
        "if RENEW_TRAIN_DATASET_FLAG:\n",
        "    if EVALUATE_ENSEMBLE_FLAG:\n",
        "        print('Do not need to renew train dataset when evaluating ensemble models')\n",
        "        assert not EVALUATE_ENSEMBLE_FLAG\n",
        "\n",
        "    random.seed(SEED_NUM)\n",
        "\n",
        "    shutil.rmtree(TRAIN_NAIP_DIRECTORY, ignore_errors = True)\n",
        "    shutil.rmtree(TRAIN_NLCD_DIRECTORY, ignore_errors = True)\n",
        "\n",
        "    ris_dl = random.sample(range(len(df)), k = NUM_WE_SELECT)\n",
        "    df_dl = df.iloc[ris_dl]\n",
        "\n",
        "    start_time = time.time()\n",
        "    for _, url in tqdm(enumerate(df_dl['image_fn'])):\n",
        "        download_file(save_path = TRAIN_NAIP_DIRECTORY, save_file_name = url[65:], url = url)\n",
        "    for _, url in tqdm(enumerate(df_dl['label_fn'])):\n",
        "        download_file(save_path = TRAIN_NLCD_DIRECTORY, save_file_name = url[65:], url = url)\n",
        "\n",
        "    time_lapsed = time.time() - start_time\n",
        "    print(f'\\n{time_lapsed // 60} min {int(time_lapsed % 60)} sec lapsed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjk3dU4om3Q"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9u21u0KXBUW"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZnGe13k9eki"
      },
      "outputs": [],
      "source": [
        "class FCN1l(nn.Module):\n",
        "    # Simplest FCN model reducing to multinomial Logistic regression model\n",
        "    # Input: 4D tensor (batch_size, num_input_channels, input_size, input_size)\n",
        "\n",
        "    def __init__(self, num_input_channels, num_output_classes, kernel_size = 3, padding = 1):\n",
        "        super(FCN1l, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(num_input_channels, num_output_classes, kernel_size = kernel_size, stride = 1, padding = padding)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "\n",
        "        return x  # Output: 4D tensor (batch_size, num_output_classes, input_size, input_size)\n",
        "\n",
        "class FCN5l(nn.Module):\n",
        "    # FCN model with 5 layers\n",
        "    # Input: 4D tensor (batch_size, num_input_channels, input_size, input_size)\n",
        "\n",
        "    def __init__(self, num_input_channels, num_output_classes, kernel_size = 3, padding = 1, num_filters = 64):\n",
        "        super(FCN5l, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(num_input_channels, num_filters, kernel_size = kernel_size, stride = 1, padding = padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters,        num_filters, kernel_size = kernel_size, stride = 1, padding = padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters,        num_filters, kernel_size = kernel_size, stride = 1, padding = padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters,        num_filters, kernel_size = kernel_size, stride = 1, padding = padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters,        num_filters, kernel_size = kernel_size, stride = 1, padding = padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters, num_output_classes, kernel_size = 1          , stride = 1, padding = 0)\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        return self.layers(inputs)  # Output: 4D tensor (batch_size, num_output_classes, input_size, input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZBbAklgYQqk"
      },
      "outputs": [],
      "source": [
        "def padding(image_np, rgb_or_gray = \"rgb\", image_or_label = \"image\"):\n",
        "    if (image_or_label == \"image\") and (rgb_or_gray == \"rgb\"):\n",
        "        width, height = image_np.shape[1], image_np.shape[2]\n",
        "    else:\n",
        "        width, height = image_np.shape[0], image_np.shape[1]\n",
        "\n",
        "    pw_x_bef = int((3880 - width) / 2)\n",
        "    pw_x_aft = 3880 - width - pw_x_bef\n",
        "    pw_y_bef = int((3880 - height) / 2)\n",
        "    pw_y_aft = 3880 - height - pw_y_bef\n",
        "    \n",
        "    if rgb_or_gray == \"rgb\":\n",
        "        if image_or_label == \"image\":\n",
        "            pad_width = ((0, 0), (pw_x_bef, pw_x_aft), (pw_y_bef, pw_y_aft))\n",
        "        elif image_or_label == \"label\":\n",
        "            pad_width = ((pw_x_bef, pw_x_aft), (pw_y_bef, pw_y_aft), (0, 0))\n",
        "        else:\n",
        "            print ('Specify image_or_label by \"image\" or \"label\"')\n",
        "            sys.exit(1)\n",
        "\n",
        "        image_np = np.pad(image_np, pad_width,\n",
        "                          constant_values = ((0, 0), (0, 0), (0, 0)))\n",
        "    elif rgb_or_gray == \"gray\": # if rgb_or_gray == \"gray\", image_or_label = \"label\"\n",
        "        image_np = np.pad(image_np, ((pw_x_bef, pw_x_aft), (pw_y_bef, pw_y_aft)),\n",
        "                          constant_values = ((4, 4), (4, 4)))\n",
        "    else:\n",
        "        print ('Specify rgb_or_gray by \"rgb\" or \"gray\"')\n",
        "        sys.exit(1)\n",
        "    \n",
        "    return(image_np, pw_x_bef, pw_x_aft, pw_y_bef, pw_y_aft)\n",
        "\n",
        "def make_image_data(image_path, image_loader):\n",
        "    image_np_s = []\n",
        "    image_np_org_s = []\n",
        "    pad_width = {'pw_x_bef': [], 'pw_x_aft': [], 'pw_y_bef': [], 'pw_y_aft': []}\n",
        "    for file in image_loader:\n",
        "        ds = gdal.Open(os.path.join(image_path, file), gdal.GA_ReadOnly)\n",
        "        image_np = np.array([ds.GetRasterBand(i + 1).ReadAsArray() for i in range(ds.RasterCount)])\n",
        "        image_np, pw_x_bef, pw_x_aft, pw_y_bef, pw_y_aft = padding(image_np, rgb_or_gray = \"rgb\", image_or_label = \"image\")\n",
        "\n",
        "        image_np_org_s.append(image_np)\n",
        "        year = file[-8:-4]\n",
        "        image_np = (image_np - np.array(MEAN_STD[year]['mean']).reshape(4,1,1)) / \\\n",
        "                        np.array(MEAN_STD[year]['std']).reshape(4,1,1)\n",
        "        pad_width['pw_x_bef'].append(pw_x_bef)\n",
        "        pad_width['pw_x_aft'].append(pw_x_aft)\n",
        "        pad_width['pw_y_bef'].append(pw_y_bef)\n",
        "        pad_width['pw_y_aft'].append(pw_y_aft)\n",
        "\n",
        "        for i in range(NUM_SPLITS):\n",
        "            for ii in range(NUM_SPLITS):\n",
        "                image_np_s.append(image_np[:, i * SPL_WH:(i + 1) * SPL_WH, ii * SPL_WH:(ii + 1) * SPL_WH])            \n",
        "\n",
        "    image_np_org_s = np.array(image_np_org_s)\n",
        "    image_np_s = np.array(image_np_s)\n",
        "    assert image_np_s.shape == (len(image_loader) * NUM_SPLITS ** 2, 4, SPL_WH, SPL_WH)\n",
        "\n",
        "    image_data = torch.from_numpy(image_np_s).float().to(device)\n",
        "    return(image_data, image_np_s, image_np_org_s, pad_width)\n",
        "\n",
        "def make_test_targets(label_path):\n",
        "    test_label_np_s = []\n",
        "    test_label_loader = sorted([file for file in os.listdir(label_path) if file.endswith('.npy') and (file.find(\"gray\") > -1)])\n",
        "    for file in test_label_loader:\n",
        "        test_label_np = np.load(os.path.join(label_path, file), gdal.GA_ReadOnly)\n",
        "        test_label_np, _, _, _, _ = padding(test_label_np, rgb_or_gray = \"gray\", image_or_label = \"label\")\n",
        "        for i in range(NUM_SPLITS):\n",
        "            for ii in range(NUM_SPLITS):\n",
        "                test_label_np_s.append(test_label_np[i * SPL_WH:(i + 1) * SPL_WH, ii * SPL_WH:(ii + 1) * SPL_WH])\n",
        "\n",
        "    test_label_np_s = np.array(test_label_np_s)\n",
        "    assert test_label_np_s.shape == (len(test_label_loader) * NUM_SPLITS ** 2, SPL_WH, SPL_WH)\n",
        "\n",
        "    test_targets = torch.from_numpy(test_label_np_s).type(torch.LongTensor).to(device)\n",
        "    return(test_targets, test_label_np_s)\n",
        "\n",
        "def calc_IoU(pred_label, g_truth_label, calc_label):\n",
        "    isect = torch.sum(10 * pred_label + g_truth_label == 11 * calc_label)\n",
        "    union = torch.sum(pred_label == calc_label) + torch.sum(g_truth_label == calc_label) - isect\n",
        "\n",
        "    return(isect / union)\n",
        "    \n",
        "def reshape_data(data):\n",
        "    num_data = int(data.shape[0] / NUM_SPLITS ** 2)\n",
        "    if data.ndim == 4:\n",
        "        reshaped_data = np.empty((0, 4, 3880, 3880))\n",
        "        for n in range(num_data):\n",
        "            reshaped_data_r = np.empty((1, 4, 0, 3880))\n",
        "            for i in range(NUM_SPLITS):\n",
        "                reshaped_data_c = np.empty((1, 4, SPL_WH, 0))\n",
        "                for ii in range(NUM_SPLITS):\n",
        "                    reshaped_data_c = np.append(reshaped_data_c, data[[n * NUM_SPLITS ** 2 + i * NUM_SPLITS + ii], :, :, :], 3)\n",
        "                reshaped_data_r = np.append(reshaped_data_r, reshaped_data_c, 2)\n",
        "            reshaped_data = np.append(reshaped_data, reshaped_data_r, 0)\n",
        "    else:\n",
        "        reshaped_data = np.empty((0, 3880, 3880))\n",
        "        for n in range(num_data):\n",
        "            reshaped_data_r = np.empty((1, 0, 3880))\n",
        "            for i in range(NUM_SPLITS):\n",
        "                reshaped_data_c = np.empty((1, SPL_WH, 0))\n",
        "                for ii in range(NUM_SPLITS):\n",
        "                    reshaped_data_c = np.append(reshaped_data_c, data[[n * NUM_SPLITS ** 2 + i * NUM_SPLITS + ii], :, :], 2)\n",
        "                reshaped_data_r = np.append(reshaped_data_r, reshaped_data_c, 1)\n",
        "            reshaped_data = np.append(reshaped_data, reshaped_data_r, 0)\n",
        "\n",
        "    return(reshaped_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZzNtEVvM4Rl"
      },
      "outputs": [],
      "source": [
        "def training(model, optimizer, epoch, bsize, ite_show_log = 32, chain_flag = False, chain_num = 1,\n",
        "             losses = [], test_losses = [], l_IoU = [[]], l_test_IoU = [[]]):    \n",
        "    def make_train_targets(label_path, ris, chain_flag = False, chain_num = 1):\n",
        "        label_np_s = []\n",
        "        label_loader = sorted([file for file in os.listdir(label_path) if file.endswith('.tif')])\n",
        "        for file in [label_loader[ri] for ri in ris]:\n",
        "            ds = gdal.Open(os.path.join(label_path, file), gdal.GA_ReadOnly)\n",
        "            label_np = np.array([ds.GetRasterBand(i + 1).ReadAsArray() for i in range(ds.RasterCount)])\n",
        "            label_np = np.squeeze(label_np)\n",
        "            if not(chain_flag and (chain_num > 1)):\n",
        "                for i, ele in enumerate(NLCD_CLASSES):\n",
        "                    label_np = np.where(label_np == ele, NLCD_IDX_TO_REDUCED_LC_MAP[i], label_np)\n",
        "            label_np, _, _, _, _ = padding(label_np, rgb_or_gray = \"gray\", image_or_label = \"label\")\n",
        "            \n",
        "            for i in range(NUM_SPLITS):\n",
        "                for ii in range(NUM_SPLITS):\n",
        "                    label_np_s.append(label_np[i * SPL_WH:(i + 1) * SPL_WH, ii * SPL_WH:(ii + 1) * SPL_WH].tolist())\n",
        "\n",
        "        label_np_s = np.array(label_np_s)\n",
        "        assert label_np_s.shape == (len(ris) * NUM_SPLITS ** 2, SPL_WH, SPL_WH)\n",
        "\n",
        "        train_targets = torch.from_numpy(label_np_s).type(torch.LongTensor).to(device)\n",
        "        return(train_targets)\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    !nvidia-smi\n",
        "    criterion = nn.CrossEntropyLoss(weight = torch.tensor(LOSS_WEIGHT).type(torch.cuda.FloatTensor).to(device))\n",
        "    for i in range(NUM_DFC2021_CLASS - len(l_IoU)): l_IoU.append([]), l_test_IoU.append([])\n",
        "\n",
        "    epo1_ite_num = int(NUM_WE_SELECT / bsize)\n",
        "    for ite in tqdm(range(epoch * epo1_ite_num)):\n",
        "        ## Train\n",
        "        ris = random.sample(range(NUM_WE_SELECT), k = bsize)\n",
        "        image_loader = sorted([file for file in os.listdir(TRAIN_NAIP_DIRECTORY) if file.endswith('.tif')])\n",
        "        image_loader = [image_loader[ri] for ri in ris]\n",
        "        train_data, _, _, _ = make_image_data(image_path = TRAIN_NAIP_DIRECTORY, image_loader = image_loader)\n",
        "\n",
        "        if chain_flag and (chain_num > 1):\n",
        "            chain_prev_n_directory = CHAIN_OUTPUT_DIRECTORY + OUTPUT_FILES_NAME + '_model_' + str(chain_num - 1) + '/'\n",
        "            train_targets = make_train_targets(label_path = chain_prev_n_directory, ris = ris,\n",
        "                                               chain_flag = chain_flag, chain_num = chain_num)\n",
        "        else:\n",
        "            train_targets = make_train_targets(label_path = TRAIN_NLCD_DIRECTORY, ris = ris,\n",
        "                                               chain_flag = chain_flag, chain_num = chain_num)\n",
        "\n",
        "        preds_s = np.empty((0, SPL_WH, SPL_WH))\n",
        "        for i in range(int(train_data.shape[0] / bsize)):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(train_data[i * bsize:(i + 1) * bsize])\n",
        "            preds = torch.max(outputs, dim = 1).indices\n",
        "            preds_s = np.append(preds_s, preds.to('cpu').detach().numpy().copy(), 0)\n",
        "            loss = criterion(outputs, train_targets[i * bsize:(i + 1) * bsize])\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        if train_data.shape[0] % bsize > 0:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(train_data[(i + 1) * bsize:])\n",
        "            preds = torch.max(outputs, dim = 1).indices\n",
        "            preds_s = np.append(preds_s, preds.to('cpu').detach().numpy().copy(), 0)\n",
        "            loss = criterion(outputs, train_targets[(i + 1) * bsize:])\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()   \n",
        "\n",
        "        preds_s = torch.tensor(preds_s).to(device)\n",
        "        for i in range(NUM_DFC2021_CLASS): l_IoU[i].append(calc_IoU(preds_s, train_targets, i).item())\n",
        " \n",
        "        if ite == 0:\n",
        "            print(\"\\nmemory_usage_after_train\")\n",
        "            print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "            print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "            print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "\n",
        "        ## Test\n",
        "        if ite == 0:\n",
        "            test_image_loader = sorted([file for file in os.listdir(TEST_NAIP_DIRECTORY) if file.endswith('.tif')])\n",
        "            test_data, test_image_np_s, test_image_np_org_s, _ = make_image_data(image_path = TEST_NAIP_DIRECTORY, image_loader = test_image_loader)\n",
        "            test_targets, test_label_np_s = make_test_targets(label_path = TEST_HR_NP_PNG_PATH)\n",
        "\n",
        "        test_preds_s = np.empty((0, SPL_WH, SPL_WH))\n",
        "        for i in range(int(test_data.shape[0] / bsize)):\n",
        "            test_outputs = model(test_data[i * bsize:(i + 1) * bsize])\n",
        "            test_preds = torch.max(test_outputs, dim = 1).indices\n",
        "            test_preds_s = np.append(test_preds_s, test_preds.to('cpu').detach().numpy().copy(), 0)\n",
        "            test_loss = criterion(test_outputs, test_targets[i * bsize:(i + 1) * bsize])\n",
        "        \n",
        "        test_losses.append(test_loss.item())\n",
        "        if test_data.shape[0] % bsize > 0:\n",
        "            test_outputs = model(test_data[(i + 1) * bsize:])\n",
        "            test_preds = torch.max(test_outputs, dim = 1).indices\n",
        "            test_preds_s = np.append(test_preds_s, test_preds.to('cpu').detach().numpy().copy(), 0)\n",
        "\n",
        "        test_preds_s = torch.tensor(test_preds_s).to(device)\n",
        "        for i in range(NUM_DFC2021_CLASS): l_test_IoU[i].append(calc_IoU(test_preds_s, test_targets, i).item())\n",
        "        if ite == 0:\n",
        "            print(\"\\nmemory_usage_after_test\")\n",
        "            print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "            print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "            print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "\n",
        "        time_lapsed = time.time() - start_time\n",
        "        if ite % ite_show_log == 0:\n",
        "            print(f'\\n{int(time_lapsed // 60)} min {int(time_lapsed % 60)} sec lapsed, \\n \\\n",
        "                    {ite} steps: Loss = {losses[-1]:.4f}, Test Loss = {test_losses[-1]:.4f}, \\n \\\n",
        "                    IoU (Water) = {l_IoU[0][-1]:.4f}, IoU (Tree Canopy) = {l_IoU[1][-1]:.4f}, \\n \\\n",
        "                    IoU (Low Vegetation) = {l_IoU[2][-1]:.4f}, IoU (Impervious) = {l_IoU[3][-1]:.4f}, \\n \\\n",
        "                    Test IoU (Water) = {l_test_IoU[0][-1]:.4f}, Test IoU (Tree Canopy) = {l_test_IoU[1][-1]:.4f}, \\n \\\n",
        "                    Test IoU (Low Vegetation) = {l_test_IoU[2][-1]:.4f}, Test IoU (Impervious) = {l_test_IoU[3][-1]:.4f}'\n",
        "                    )\n",
        "        if ((ite + 1) % epo1_ite_num == 0):# and int((ite + 1) / epo1_ite_num) > 4:\n",
        "            print('\\naverage test losses in this epoch:', np.mean(test_losses[-epo1_ite_num:]))\n",
        "            print('rate of change of average test losses in this epoch from the previous one:',\n",
        "                  (np.mean(test_losses[-epo1_ite_num * 2:-epo1_ite_num]) - np.mean(test_losses[-epo1_ite_num:])) / np.mean(test_losses[-epo1_ite_num:]))\n",
        "            \n",
        "    \n",
        "    test_preds_s = torch.from_numpy(reshape_data(test_preds_s.to('cpu').detach().numpy().copy())).to(device)\n",
        "    test_label_np_s = torch.from_numpy(reshape_data(test_label_np_s)).to(device)\n",
        "\n",
        "    print(f'\\n{time_lapsed // 60} min {int(time_lapsed % 60)} sec lapsed')\n",
        "    return(model, losses, test_losses, l_IoU, l_test_IoU, test_preds_s, test_image_np_s, test_image_np_org_s, test_label_np_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-21CTpETXqn"
      },
      "outputs": [],
      "source": [
        "def reshape_and_save_tif(preds, pw_x_bef, pw_x_aft, pw_y_bef, pw_y_aft, file, naip_directory, save_directory):\n",
        "    if pw_x_aft > 0:\n",
        "        preds = preds[pw_x_bef:-pw_x_aft, :]\n",
        "    else:\n",
        "        preds = preds[pw_x_bef:, :]\n",
        "    if pw_y_aft > 0:\n",
        "        preds = preds[:, pw_y_bef:-pw_y_aft]\n",
        "    else:\n",
        "        preds = preds[:, pw_y_bef:]\n",
        "        \n",
        "    with rasterio.open(os.path.join(naip_directory, file)) as f:\n",
        "        input_profile = f.profile.copy()\n",
        "\n",
        "    output_profile = input_profile.copy()\n",
        "    output_profile[\"driver\"] = \"GTiff\"\n",
        "    output_profile[\"dtype\"] = \"uint8\"\n",
        "    output_profile[\"count\"] = 1\n",
        "    output_profile[\"nodata\"] = 0\n",
        "\n",
        "    output_fn = file.replace(\"naip\", \"predictions\")\n",
        "    output_fn = os.path.join(save_directory, output_fn)\n",
        "    with rasterio.open(output_fn, \"w\", **output_profile) as f:\n",
        "        f.write(preds, 1)\n",
        "\n",
        "def make_save_preds(model, bsize, image_loader, naip_dir, save_pred_dir, codalab_flag):\n",
        "    def batch_make_save(model, bsize, image_loader, naip_dir, save_pred_dir, codalab_flag):\n",
        "        data, _, _, pad_width = make_image_data(image_path = naip_dir, image_loader = image_loader)\n",
        "\n",
        "        preds_s = np.empty((0, SPL_WH, SPL_WH))\n",
        "        for i in range(int(data.shape[0] / bsize)):\n",
        "            outputs = model(data[i * bsize:(i + 1) * bsize])\n",
        "            preds = torch.max(outputs, dim = 1).indices\n",
        "            preds_s = np.append(preds_s, preds.to('cpu').detach().numpy().copy(), 0)\n",
        "\n",
        "        if data.shape[0] % bsize > 0:\n",
        "            outputs = model(data[(i + 1) * bsize:])\n",
        "            preds = torch.max(outputs, dim = 1).indices\n",
        "            preds_s = np.append(preds_s, preds.to('cpu').detach().numpy().copy(), 0)\n",
        "\n",
        "        reshaped_preds_s = reshape_data(preds_s).reshape([-1, 3880, 3880])\n",
        "        num_data = len(image_loader)\n",
        "        assert reshaped_preds_s.shape == (num_data, 3880, 3880)\n",
        "\n",
        "        if codalab_flag:\n",
        "            # Class \"None\" -> modified to \"Tree Canopy\" (because TC is most prevalent)\n",
        "            reshaped_preds_s[reshaped_preds_s == 4] = 1\n",
        "\n",
        "        for n in range(num_data):\n",
        "            reshape_and_save_tif(preds = reshaped_preds_s[n], pw_x_bef = pad_width['pw_x_bef'][n],\n",
        "                                 pw_x_aft = pad_width['pw_x_aft'][n], pw_y_bef = pad_width['pw_y_bef'][n],\n",
        "                                 pw_y_aft = pad_width['pw_y_aft'][n], file = image_loader[n],\n",
        "                                 naip_directory = naip_dir, save_directory = save_pred_dir)\n",
        "\n",
        "\n",
        "    shutil.rmtree(save_pred_dir, ignore_errors = True)\n",
        "    os.makedirs(save_pred_dir, exist_ok = True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for ite in tqdm(range(int(len(image_loader) / bsize))):\n",
        "        batch_make_save(model = model, bsize = bsize, image_loader = image_loader[(ite * bsize):((ite + 1) * bsize)],\n",
        "                        naip_dir = naip_dir, save_pred_dir = save_pred_dir, codalab_flag = codalab_flag)\n",
        "    if len(image_loader) % bsize > 0:\n",
        "        batch_make_save(model = model, bsize = bsize, image_loader = image_loader[((ite + 1) * bsize):],\n",
        "                        naip_dir = naip_dir, save_pred_dir = save_pred_dir, codalab_flag = codalab_flag)\n",
        "        \n",
        "    print(\"\\nmemory_usage_after_making_preds\")\n",
        "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "\n",
        "    time_lapsed = time.time() - start_time\n",
        "    print(f'\\n{time_lapsed // 60} min {int(time_lapsed % 60)} sec lapsed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlUocD3hAj6_"
      },
      "outputs": [],
      "source": [
        "def make_rgb_label(label_np):\n",
        "    \"\"\"\n",
        "    0: Water, 1: Tree Canopy, 2: Low Vegetation, 3: Impervious\n",
        "    light blue: Water, dark green: Tree Canopy, light green: Low Vegetation, red: Impervious\n",
        "    \"\"\"\n",
        "    label_np_rgb = np.zeros((len(label_np), 3880, 3880, 3), dtype = np.uint8)\n",
        "    for i in range(len(label_np)):\n",
        "        label_np_rgb[i][label_np[i] == 0, :] = [0, 225, 225]\n",
        "        label_np_rgb[i][label_np[i] == 1, :] = [0, 128, 0]\n",
        "        label_np_rgb[i][label_np[i] == 2, :] = [0, 225, 0]\n",
        "        label_np_rgb[i][label_np[i] == 3, :] = [255, 0, 0]\n",
        "\n",
        "    return(label_np_rgb)\n",
        "\n",
        "def visualize_save_pred(test_preds, test_image_np_org_s, chain_flag, chain_num,\n",
        "                        uncertainty_s = [], ex_flag = False):\n",
        "    titles = []\n",
        "    test_label_loader_rgb = sorted([file for file in os.listdir(TEST_HR_NP_PNG_PATH)\n",
        "                                    if file.endswith('.npy') and (file.find(\"rgb\") > -1)])\n",
        "    for fn in test_label_loader_rgb: titles.append(re.search('-.*\\.', fn).group()[1:-1])\n",
        "    num_file = len(test_label_loader_rgb)\n",
        "    \n",
        "    hr_label_s_rgb = []\n",
        "    for file in test_label_loader_rgb:\n",
        "        if file.endswith('.npy'):\n",
        "            test_label_np_rgb = np.load(os.path.join(TEST_HR_NP_PNG_PATH, file), gdal.GA_ReadOnly)\n",
        "            padded_hr_label_rgb, _, _, _, _ = padding(test_label_np_rgb, rgb_or_gray = \"rgb\", image_or_label = \"label\")\n",
        "            hr_label_s_rgb.append(padded_hr_label_rgb)\n",
        "\n",
        "    if test_preds.dtype == 'float64':\n",
        "        test_preds_np_rgb = make_rgb_label(test_preds)\n",
        "    else:\n",
        "        test_preds_np_rgb = make_rgb_label(test_preds.to('cpu').detach().numpy().copy())    \n",
        "\n",
        "    nlcd_np_s = []\n",
        "    test_nlcd_loader = sorted([file for file in os.listdir(TEST_NLCD_DIRECTORY) if file.endswith('.tif')])\n",
        "    for file in test_nlcd_loader:\n",
        "        ds = gdal.Open(os.path.join(TEST_NLCD_DIRECTORY, file), gdal.GA_ReadOnly)\n",
        "        label_np = np.array([ds.GetRasterBand(i + 1).ReadAsArray() for i in range(ds.RasterCount)])\n",
        "        label_np = np.squeeze(label_np)\n",
        "        for i, ele in enumerate(NLCD_CLASSES):\n",
        "            label_np = np.where(label_np == ele, NLCD_IDX_TO_REDUCED_LC_MAP[i], label_np)\n",
        "\n",
        "        padded_ncld_np, _, _, _, _ = padding(label_np, rgb_or_gray = \"gray\", image_or_label = \"label\")\n",
        "        nlcd_np_s.append(padded_ncld_np)\n",
        "\n",
        "    nlcd_np_s_rgb = make_rgb_label(nlcd_np_s)\n",
        "    test_image_np_org_s = test_image_np_org_s.astype(np.uint8)\n",
        "\n",
        "    print(titles)\n",
        "    fig, ax = plt.subplots(num_file, 4, figsize = (20, 10 * int(num_file / 2)))\n",
        "    ax[0, 0].set_title('NAIP image')\n",
        "    ax[0, 1].set_title('Ground truth')\n",
        "    ax[0, 2].set_title('Prediction')\n",
        "    ax[0, 3].set_title('NLCD label')\n",
        "\n",
        "    for i in range(num_file):\n",
        "        ax[i, 0].imshow(np.transpose(test_image_np_org_s[i], (1, 2, 0))[:, :, :3])\n",
        "        ax[i, 1].imshow(hr_label_s_rgb[i])\n",
        "        ax[i, 2].imshow(test_preds_np_rgb[i])\n",
        "        ax[i, 3].imshow(nlcd_np_s_rgb[i])\n",
        "\n",
        "    os.makedirs(OUTPUT_IMAGE_DIRECTORY, exist_ok = True)\n",
        "    output_name = OUTPUT_IMAGE_DIRECTORY + OUTPUT_FILES_NAME\n",
        "    if EVALUATE_ENSEMBLE_FLAG:\n",
        "        output_name = output_name + '_ENS_EVAL_M' + str(NUM_ENSEMBLE)\n",
        "        if ex_flag:\n",
        "            output_name = output_name + '_ex'\n",
        "            print('one_example_model')\n",
        "        else:\n",
        "            print('ensemble_model')\n",
        "    if chain_flag:\n",
        "        output_name = output_name + '_model_' + str(chain_num)\n",
        "\n",
        "    fig.savefig(output_name +'_aligned_preds.png', dpi = fig.dpi)\n",
        "    plt.show()\n",
        "\n",
        "    if EVALUATE_ENSEMBLE_FLAG:\n",
        "        print('\\nplot considering uncertainty:\\n', titles)\n",
        "        fig, ax = plt.subplots(num_file, 4, figsize = (20, 10 * int(num_file / 2)))\n",
        "        ax[0, 0].set_title('NAIP image')\n",
        "        ax[0, 1].set_title('Ground truth')\n",
        "        ax[0, 2].set_title('Prediction')\n",
        "        ax[0, 3].set_title('NLCD label')\n",
        "\n",
        "        for i in range(test_preds_np_rgb.shape[3]):\n",
        "            test_preds_np_rgb[:, :, :, i] = np.clip(test_preds_np_rgb[:, :, :, i] + 255 * uncertainty_s, 0, 255)\n",
        "        test_preds_np_rgb = test_preds_np_rgb.astype(np.uint8)\n",
        "        for i in range(num_file):\n",
        "            ax[i, 0].imshow(np.transpose(test_image_np_org_s[i], (1, 2, 0))[:, :, :3])\n",
        "            ax[i, 1].imshow(hr_label_s_rgb[i])\n",
        "            ax[i, 2].imshow(test_preds_np_rgb[i])\n",
        "            ax[i, 3].imshow(nlcd_np_s_rgb[i])\n",
        "\n",
        "        if ex_flag:\n",
        "            print('one_example_model')\n",
        "        else:\n",
        "            print('ensemble_model')\n",
        "\n",
        "        fig.savefig(output_name +'_aligned_preds_unc.png', dpi = fig.dpi)\n",
        "        plt.show()\n",
        "\n",
        "    return(titles, num_file, hr_label_s_rgb, test_preds_np_rgb, nlcd_np_s, nlcd_np_s_rgb)\n",
        "\n",
        "def plot_save_log(losses, test_losses, IoU, test_IoU, output_name, none_flag = True):\n",
        "    output_path = OUTPUT_IMAGE_DIRECTORY + output_name\n",
        "\n",
        "    fig = plt.figure(figsize = (16, 4))\n",
        "    plt.plot(losses, label = 'train')\n",
        "    plt.plot(test_losses, label = 'test')\n",
        "    plt.xlabel('# Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss plot')\n",
        "    fig.savefig(output_path +'_loss.png', dpi = fig.dpi)\n",
        "    plt.show()\n",
        "\n",
        "    all_class_names = ['Water', 'Tree Canopy', 'Low Vegetation', 'Impervious', 'None']\n",
        "    if not(none_flag):\n",
        "        IoU = IoU[:-1]\n",
        "        test_IoU = test_IoU[:-1]\n",
        "        all_class_names = all_class_names[:-1]\n",
        "        output_path = output_path + '_wo_None'\n",
        "\n",
        "    fig = plt.figure(figsize = (16, 4))\n",
        "    for i, ious in enumerate(IoU):\n",
        "        ious = pd.Series(ious).rolling(1).mean()\n",
        "        plt.plot(ious, label = all_class_names[i])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlabel('# Steps')\n",
        "    plt.ylabel('Train IoU')\n",
        "    plt.title('Train IoU plot (smoothed)')\n",
        "    fig.savefig(output_path + '_Train_IoU.png', dpi = fig.dpi)\n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure(figsize = (16, 4))\n",
        "    for i, ious in enumerate(test_IoU):\n",
        "        plt.plot(ious, label = all_class_names[i])\n",
        "    plt.legend()\n",
        "    plt.xlabel('# Steps')\n",
        "    plt.ylabel('Test IoU')\n",
        "    plt.title('Test IoU plot')\n",
        "    fig.savefig(output_path + '_Test_IoU.png', dpi = fig.dpi)\n",
        "    plt.show()\n",
        "\n",
        "def save_plot_outputs(losses, test_losses, IoU, test_IoU, test_preds, test_image_np_s, test_image_np_org_s,\n",
        "                      test_label_np_s, chain_flag = False, chain_cont_flag = False, chain_num = 1):\n",
        "    if chain_flag:\n",
        "        _ = visualize_save_pred(test_preds, test_image_np_org_s, chain_flag, chain_num)\n",
        "        output_name = OUTPUT_FILES_NAME + '_model_' + str(chain_num)\n",
        "    else:\n",
        "        output_name = OUTPUT_FILES_NAME\n",
        "\n",
        "    os.makedirs(TRAINED_OBJECT_DIRECTORY, exist_ok = True)\n",
        "    torch.save(model.state_dict(), TRAINED_OBJECT_DIRECTORY + 'trained_model_' + output_name + '.pth')\n",
        "    torch.save(optimizer.state_dict(), TRAINED_OBJECT_DIRECTORY + 'trained_optimizer_' + output_name + '.pth')\n",
        "    trained_objects = losses, test_losses, IoU, test_IoU, test_preds, test_image_np_s, test_image_np_org_s, test_label_np_s\n",
        "    pd.to_pickle(trained_objects, TRAINED_OBJECT_DIRECTORY + 'trained_objects_' + output_name + '.pkl')\n",
        "\n",
        "    plot_save_log(losses, test_losses, IoU, test_IoU, output_name, none_flag = True)\n",
        "    plot_save_log(losses, test_losses, IoU, test_IoU, output_name, none_flag = False)\n",
        "\n",
        "    if chain_cont_flag:\n",
        "        del globals()['model'], globals()['losses'], globals()['test_losses'], globals()['IoU'], globals()['test_IoU']\n",
        "        del globals()['test_preds'], globals()['test_image_np_s'], globals()['test_image_np_org_s'], globals()['test_label_np_s']\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP1e_LXzdph7"
      },
      "outputs": [],
      "source": [
        "def calc_preds_unc(models, image_path, image_loader, codalab_flag = False):\n",
        "    from scipy.stats import entropy\n",
        "\n",
        "    test_data, test_image_np_s, test_image_np_org_s, pad_width = \\\n",
        "            make_image_data(image_path = image_path, image_loader = image_loader)\n",
        "    probs_models = np.empty((0, len(image_loader), NUM_DFC2021_CLASS, 3880, 3880))\n",
        "    for model in models:\n",
        "        probs_s = np.empty((0, NUM_DFC2021_CLASS, SPL_WH, SPL_WH))\n",
        "        for i in range(int(test_data.shape[0] / BATCH)):\n",
        "            outputs = model(test_data[i * BATCH:(i + 1) * BATCH])\n",
        "            probs = nn.Softmax(dim = 1)(outputs)\n",
        "            probs_s = np.append(probs_s, probs.to('cpu').detach().numpy().copy(), 0)\n",
        "        if test_data.shape[0] % BATCH > 0:\n",
        "            outputs = model(test_data[(i + 1) * BATCH:])\n",
        "            probs = nn.Softmax(dim = 1)(outputs)\n",
        "            probs_s = np.append(probs_s, probs.to('cpu').detach().numpy().copy(), 0)\n",
        "\n",
        "        reshaped_probs_s = np.empty((len(image_loader), 0, 3880, 3880))\n",
        "        for i in range(NUM_DFC2021_CLASS):\n",
        "            reshaped_probs_s = np.append(reshaped_probs_s, reshape_data(probs_s[:, i, :, :]).reshape([-1, 1, 3880, 3880]), 1)\n",
        "        assert reshaped_probs_s.shape == (len(image_loader), NUM_DFC2021_CLASS, 3880, 3880)\n",
        "        probs_models = np.append(probs_models, reshaped_probs_s.reshape([1, len(image_loader), NUM_DFC2021_CLASS, 3880, 3880]), 0)\n",
        "\n",
        "    probs_ens = probs_models.mean(axis = 0)\n",
        "    preds_ens = np.argmax(probs_ens, axis = 1)\n",
        "    if codalab_flag:\n",
        "        uncertainty_ens = []\n",
        "        preds_model_ex = []\n",
        "        uncertainty_model_ex = []\n",
        "    else:\n",
        "        uncertainty_ens = entropy(probs_ens, axis = 1) / np.log(NUM_DFC2021_CLASS)\n",
        "        preds_model_ex = np.argmax(probs_models[0], axis = 1)\n",
        "        uncertainty_model_ex = entropy(probs_models[0], axis = 1) / np.log(NUM_DFC2021_CLASS)\n",
        "\n",
        "    return(preds_ens, uncertainty_ens, preds_model_ex, uncertainty_model_ex, test_image_np_org_s, pad_width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x3KB3EBW3eT"
      },
      "source": [
        "## Run Training and Visualizing Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdgfCuStCsYv"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)        #GPU: cuda:0, CPU: cpu\n",
        "\n",
        "chain_flag = True if len(MODEL_LIST) > 1 else False\n",
        "\n",
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    model_name = MODEL_LIST[-1]\n",
        "    models = []\n",
        "    for i in range(NUM_ENSEMBLE):\n",
        "        if model_name == 'FCN1l':\n",
        "            model = FCN1l(num_input_channels = 4, num_output_classes = NUM_DFC2021_CLASS).to(device)\n",
        "        elif model_name == 'FCN5l':\n",
        "            model = FCN5l(num_input_channels = 4, num_output_classes = NUM_DFC2021_CLASS).to(device)\n",
        "        elif model_name == 'U-NET18':\n",
        "            model = smp.Unet(encoder_name = 'resnet18', encoder_depth = 3, encoder_weights = None, decoder_channels = (128, 64, 64),\n",
        "                            decoder_use_batchnorm = True, in_channels = 4, classes = NUM_DFC2021_CLASS).to(device)\n",
        "        elif model_name == 'U-NET50':\n",
        "            model = smp.Unet(encoder_name = 'resnet50', encoder_depth = 3, encoder_weights = None, decoder_channels = (128, 64, 64),\n",
        "                            decoder_use_batchnorm = True, in_channels = 4, classes = NUM_DFC2021_CLASS).to(device)\n",
        "        \n",
        "        output_file_path = TRAINED_OBJECT_DIRECTORY + 'trained_model_' + OUTPUT_FILES_NAME + '_ENS_' + str(i)\n",
        "        output_file_path = output_file_path + ('_model_' + str(len(MODEL_LIST)) + '.pth' if chain_flag else '.pth')\n",
        "        model.load_state_dict(torch.load(output_file_path))\n",
        "        models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOqD5LLV_1Zk"
      },
      "outputs": [],
      "source": [
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    start_time = time.time()\n",
        "    test_image_loader = sorted([file for file in os.listdir(TEST_NAIP_DIRECTORY) if file.endswith('.tif')])\n",
        "\n",
        "    preds_ens_s = np.empty((0, 3880, 3880))\n",
        "    uncertainty_ens_s = np.empty((0, 3880, 3880))\n",
        "    preds_model_ex_s = np.empty((0, 3880, 3880))\n",
        "    uncertainty_model_ex_s = np.empty((0, 3880, 3880))\n",
        "    test_image_np_org_s = np.empty((0, 4, 3880, 3880))\n",
        "    for ite in tqdm(range(int(len(test_image_loader) / BATCH))):\n",
        "        preds_ens, uncertainty_ens, preds_model_ex, uncertainty_model_ex, test_image_np_org, _ = \\\n",
        "                 calc_preds_unc(models = models, image_path = TEST_NAIP_DIRECTORY,\n",
        "                                image_loader = test_image_loader[(ite * BATCH):((ite + 1) * BATCH)])\n",
        "        preds_ens_s = np.append(preds_ens_s, preds_ens, 0)\n",
        "        uncertainty_ens_s = np.append(uncertainty_ens_s, uncertainty_ens, 0)\n",
        "        preds_model_ex_s = np.append(preds_model_ex_s, preds_model_ex, 0)\n",
        "        uncertainty_model_ex_s = np.append(uncertainty_model_ex_s, uncertainty_model_ex, 0)\n",
        "        test_image_np_org_s = np.append(test_image_np_org_s, test_image_np_org, 0)\n",
        "\n",
        "    if len(test_image_loader) % BATCH > 0:\n",
        "        preds_ens, uncertainty_ens, preds_model_ex, uncertainty_model_ex, test_image_np_org, _ = \\\n",
        "                calc_preds_unc(models = models, image_path = TEST_NAIP_DIRECTORY,\n",
        "                               image_loader = test_image_loader[((ite + 1) * BATCH):])\n",
        "        preds_ens_s = np.append(preds_ens_s, preds_ens, 0)\n",
        "        uncertainty_ens_s = np.append(uncertainty_ens_s, uncertainty_ens, 0)\n",
        "        preds_model_ex_s = np.append(preds_model_ex_s, preds_model_ex, 0)\n",
        "        uncertainty_model_ex_s = np.append(uncertainty_model_ex_s, uncertainty_model_ex, 0)\n",
        "        test_image_np_org_s = np.append(test_image_np_org_s, test_image_np_org, 0)\n",
        "\n",
        "    print(\"\\nmemory_usage_after_calc_test_preds_uncertainty\")\n",
        "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "\n",
        "    time_lapsed = time.time() - start_time\n",
        "    print(f'\\n{time_lapsed // 60} min {int(time_lapsed % 60)} sec lapsed')\n",
        "\n",
        "else:\n",
        "    torch.manual_seed(SEED_NUM)\n",
        "    random.seed(SEED_NUM)\n",
        "    np.random.seed(SEED_NUM)\n",
        "\n",
        "    for i, model_name in enumerate(MODEL_LIST):\n",
        "        if model_name == 'FCN1l':\n",
        "            model = FCN1l(num_input_channels = 4, num_output_classes = NUM_DFC2021_CLASS).to(device)\n",
        "        elif model_name == 'FCN5l':\n",
        "            model = FCN5l(num_input_channels = 4, num_output_classes = NUM_DFC2021_CLASS).to(device)\n",
        "        elif model_name == 'U-NET18':\n",
        "            model = smp.Unet(encoder_name = 'resnet18', encoder_depth = 3, encoder_weights = None, decoder_channels = (128, 64, 64),\n",
        "                            decoder_use_batchnorm = True, in_channels = 4, classes = NUM_DFC2021_CLASS).to(device)\n",
        "        elif model_name == 'U-NET50':\n",
        "            model = smp.Unet(encoder_name = 'resnet50', encoder_depth = 3, encoder_weights = None, decoder_channels = (128, 64, 64),\n",
        "                            decoder_use_batchnorm = True, in_channels = 4, classes = NUM_DFC2021_CLASS).to(device)\n",
        "\n",
        "        optimizer = torch.optim.RAdam(model.parameters(), lr = 0.001) #torch.optim.NAdam(model.parameters(), lr = 0.001), torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "        chain_cont_flag = True if i + 1 < len(MODEL_LIST) else False\n",
        "        model, losses, test_losses, IoU, test_IoU, test_preds, test_image_np_s, test_image_np_org_s, test_label_np_s = \\\n",
        "                    training(model, optimizer, epoch = EPOCH, bsize = BATCH, ite_show_log = 64, chain_flag = chain_flag, chain_num = i + 1,\n",
        "                            losses = [], test_losses = [], l_IoU = [[]], l_test_IoU = [[]])\n",
        "\n",
        "        if chain_cont_flag:\n",
        "            train_image_loader = sorted([file for file in os.listdir(TRAIN_NAIP_DIRECTORY) if file.endswith('.tif')])\n",
        "            chain_n_directory = CHAIN_OUTPUT_DIRECTORY + OUTPUT_FILES_NAME + '_model_' + str(i + 1) + '/'\n",
        "            make_save_preds(model = model, bsize = BATCH, image_loader = train_image_loader,\n",
        "                            naip_dir = TRAIN_NAIP_DIRECTORY, save_pred_dir = chain_n_directory, codalab_flag = True)\n",
        "\n",
        "        save_plot_outputs(losses, test_losses, IoU, test_IoU, test_preds, test_image_np_s, test_image_np_org_s,\n",
        "                        test_label_np_s, chain_flag = chain_flag, chain_cont_flag = chain_cont_flag, chain_num = i + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc6kLLfmc7sa"
      },
      "source": [
        "# Visualization of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c7osEEuEj9A"
      },
      "source": [
        "## Aligned images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvPrDgt1EdbK"
      },
      "outputs": [],
      "source": [
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    titles_ex, num_file_ex, hr_label_s_rgb_ex, test_preds_np_rgb_ex, nlcd_np_s_ex, nlcd_np_s_rgb_ex = \\\n",
        "                    visualize_save_pred(preds_model_ex_s, test_image_np_org_s, chain_flag, chain_num = len(MODEL_LIST),\n",
        "                                        uncertainty_s = uncertainty_model_ex_s, ex_flag = True)\n",
        "    titles, num_file, hr_label_s_rgb, test_preds_np_rgb, nlcd_np_s, nlcd_np_s_rgb = \\\n",
        "                    visualize_save_pred(preds_ens_s, test_image_np_org_s, chain_flag, chain_num = len(MODEL_LIST),\n",
        "                                        uncertainty_s = uncertainty_ens_s, ex_flag = False)\n",
        "else:\n",
        "    titles, num_file, hr_label_s_rgb, test_preds_np_rgb, nlcd_np_s, nlcd_np_s_rgb = \\\n",
        "                    visualize_save_pred(test_preds, test_image_np_org_s, chain_flag, chain_num = len(MODEL_LIST))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iikj926hTBM3"
      },
      "source": [
        "#IoU for Gain and Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X--g6yJat_bP"
      },
      "outputs": [],
      "source": [
        "def calc_GL_IoU(both_year_preds_np, both_year_true_labels_np):\n",
        "    by_preds_tensor = torch.tensor(both_year_preds_np + 1).reshape(-1, 2, 3880, 3880)\n",
        "    by_true_labels_tensor = torch.tensor(both_year_true_labels_np + 1).reshape(-1, 2, 3880, 3880)\n",
        "    preds_change_flag = by_preds_tensor[:, 0] != by_preds_tensor[:, 1]\n",
        "    true_change_flag = by_true_labels_tensor[:, 0] != by_true_labels_tensor[:, 1]\n",
        "\n",
        "    by_preds_tensor[:, 0] = by_preds_tensor[:, 0] * preds_change_flag\n",
        "    by_preds_tensor[:, 1] = by_preds_tensor[:, 1] * preds_change_flag\n",
        "    by_true_labels_tensor[:, 0] = by_true_labels_tensor[:, 0] * true_change_flag\n",
        "    \n",
        "    by_true_labels_tensor[:, 1] = by_true_labels_tensor[:, 1] * true_change_flag\n",
        "\n",
        "    print(\"preds_change_flag:\\n\", pd.Series(preds_change_flag.flatten()).value_counts())\n",
        "    print(\"\\ntrue_change_flag:\\n\", pd.Series(true_change_flag.flatten()).value_counts())\n",
        "\n",
        "    print(\"\\n\\n0: No Change, 1: -Water, 2: -Tree Canopy, 3: -Low Vegetation, 4: -Impervious, 5: -None\",\n",
        "          \"\\npred_label_2013:\\n\", pd.Series(by_preds_tensor[:, 0].flatten()).value_counts(),\n",
        "          \"\\n\\ntest_label_2013:\\n\", pd.Series(by_true_labels_tensor[:, 0].flatten()).value_counts())\n",
        "\n",
        "    print(\"\\n\\n0: No Change, 1: +Water, 2: +Tree Canopy, 3: +Low Vegetation, 4: +Impervious, 5: +None\",\n",
        "          \"\\npred_label_2017:\\n\", pd.Series(by_preds_tensor[:, 1].flatten()).value_counts(),\n",
        "          \"\\n\\ntest_label_2017:\\n\", pd.Series(by_true_labels_tensor[:, 1].flatten()).value_counts())\n",
        "\n",
        "    IoU = []\n",
        "    for i in range(NUM_DFC2021_CLASS - 1):\n",
        "        IoU.append(calc_IoU(by_preds_tensor[:, 0], by_true_labels_tensor[:, 0], i + 1).item())\n",
        "    for i in range(NUM_DFC2021_CLASS - 1):\n",
        "        IoU.append(calc_IoU(by_preds_tensor[:, 1], by_true_labels_tensor[:, 1], i + 1).item())\n",
        "    IoU.append(np.mean(IoU))\n",
        "\n",
        "    print(f\"\\n\\nIoU: [-W, -TC, -LV, -I, +W, +TC, +LV, +I, Avg.] = {np.round(IoU, 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkM-W3WBMx8N"
      },
      "outputs": [],
      "source": [
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    _, test_label_np_s = make_test_targets(label_path = TEST_HR_NP_PNG_PATH)\n",
        "    print('one_example_model:\\n')\n",
        "    calc_GL_IoU(preds_model_ex_s, test_label_np_s)\n",
        "    print('\\n\\nensemble_model:\\n')\n",
        "    calc_GL_IoU(preds_ens_s, test_label_np_s)\n",
        "else:\n",
        "    test_preds_ch = test_preds.to('cpu').detach().numpy().copy()\n",
        "    calc_GL_IoU(test_preds_ch, test_label_np_s.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xCel3tMwPwM"
      },
      "source": [
        "## IoU for Gain and Loss by NLCD Difference Algorithm \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1ljY0uF3Gy8"
      },
      "outputs": [],
      "source": [
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    calc_GL_IoU(np.array(nlcd_np_s), test_label_np_s)\n",
        "else:\n",
        "    calc_GL_IoU(np.array(nlcd_np_s), test_label_np_s.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf8JNvyNUyDN"
      },
      "source": [
        "# Make a zip file for submission to [Codalab](https://codalab.lisn.upsaclay.fr/competitions/7908)\n",
        "\n",
        "Codalab can then compute the test IoU(s) in exactly the same way as the DFC2021 contest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXxMH6-BPSPh"
      },
      "outputs": [],
      "source": [
        "# Use the git implementation of the 3rd place team of the DFC 2021 contest (as base-line model git does not include test_tiles.txt used below).\n",
        "!git clone https://github.com/baoqianyue/DFC2021-Track-MSD.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIfo01mpSaFW"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(ROOT_PATH + 'DFC2021-Track-MSD/data/test_tiles.txt', header = None)\n",
        "df = df.rename(columns = {0:'id'})\n",
        "\n",
        "def id_to_url_2013(id):\n",
        "    url = 'https://dfc2021.blob.core.windows.net/competition-data/naip-2013/' + str(id) + '_naip-2013.tif'\n",
        "    return url\n",
        "\n",
        "def id_to_url_2017(id):\n",
        "    url = 'https://dfc2021.blob.core.windows.net/competition-data/naip-2017/' + str(id) + '_naip-2017.tif'\n",
        "    return url\n",
        "\n",
        "df['url_2013'] = df['id'].apply(id_to_url_2013)\n",
        "df['url_2017'] = df['id'].apply(id_to_url_2017)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1H8BwicUVWm"
      },
      "outputs": [],
      "source": [
        "# Need to run the codes below once when running codes in this notebook first by setting CODALAB_NAIP_DOWNLOAD_FLAG = True.\n",
        "\n",
        "if CODALAB_NAIP_DOWNLOAD_FLAG:\n",
        "    start_time = time.time()\n",
        "    shutil.rmtree(CODALAB_NAIP_DIRECTORY, ignore_errors = True)\n",
        "    for url in df['url_2013']:\n",
        "        download_file(save_path = CODALAB_NAIP_DIRECTORY, save_file_name = url[65:], url = url)\n",
        "    for url in df['url_2017']:\n",
        "        download_file(save_path = CODALAB_NAIP_DIRECTORY, save_file_name = url[65:], url = url)\n",
        "    print((time.time() - start_time) / 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ASkzEbXVNKK"
      },
      "outputs": [],
      "source": [
        "codalab_test_image_loader = sorted([file for file in os.listdir(CODALAB_NAIP_DIRECTORY) if file.endswith('.tif')])\n",
        "\n",
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    start_time = time.time()\n",
        "\n",
        "    shutil.rmtree(CODALAB_PRED_DIRECTORY, ignore_errors = True)\n",
        "    os.makedirs(CODALAB_PRED_DIRECTORY, exist_ok = True)\n",
        "\n",
        "    for ite in tqdm(range(int(len(codalab_test_image_loader) / BATCH))):\n",
        "        image_loader = codalab_test_image_loader[(ite * BATCH):((ite + 1) * BATCH)]\n",
        "        preds_ens, _, _, _, _, pad_width = calc_preds_unc(models = models, image_path = CODALAB_NAIP_DIRECTORY,\n",
        "                                                          image_loader = image_loader, codalab_flag = True)\n",
        "        # Class \"None\" -> modified to \"Tree Canopy\" (because TC is most prevalent)\n",
        "        preds_ens[preds_ens == 4] = 1\n",
        "\n",
        "        for n in range(BATCH):\n",
        "            reshape_and_save_tif(preds = preds_ens[n], pw_x_bef = pad_width['pw_x_bef'][n],\n",
        "                                 pw_x_aft = pad_width['pw_x_aft'][n], pw_y_bef = pad_width['pw_y_bef'][n],\n",
        "                                 pw_y_aft = pad_width['pw_y_aft'][n], file = image_loader[n],\n",
        "                                 naip_directory = CODALAB_NAIP_DIRECTORY, save_directory = CODALAB_PRED_DIRECTORY)\n",
        "            \n",
        "    if len(codalab_test_image_loader) % BATCH > 0:\n",
        "        image_loader = codalab_test_image_loader[((ite + 1) * BATCH):]\n",
        "        preds_ens, _, _, _, _, pad_width = calc_preds_unc(models = models, image_path = CODALAB_NAIP_DIRECTORY,\n",
        "                                                          image_loader = image_loader, codalab_flag = True)\n",
        "        # Class \"None\" -> modified to \"Tree Canopy\" (because TC is most prevalent)\n",
        "        preds_ens[preds_ens == 4] = 1\n",
        "\n",
        "        for n in range(len(codalab_test_image_loader) % BATCH):\n",
        "            reshape_and_save_tif(preds = preds_ens[n], pw_x_bef = pad_width['pw_x_bef'][n],\n",
        "                                 pw_x_aft = pad_width['pw_x_aft'][n], pw_y_bef = pad_width['pw_y_bef'][n],\n",
        "                                 pw_y_aft = pad_width['pw_y_aft'][n], file = image_loader[n],\n",
        "                                 naip_directory = CODALAB_NAIP_DIRECTORY, save_directory = CODALAB_PRED_DIRECTORY)\n",
        "\n",
        "    print(\"\\nmemory_usage_after_calc_codalab_preds\")\n",
        "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "\n",
        "    time_lapsed = time.time() - start_time\n",
        "    print(f'\\n{time_lapsed // 60} min {int(time_lapsed % 60)} sec lapsed')\n",
        "\n",
        "else:\n",
        "    make_save_preds(model = model, bsize = BATCH, image_loader = codalab_test_image_loader,\n",
        "                    naip_dir = CODALAB_NAIP_DIRECTORY, save_pred_dir = CODALAB_PRED_DIRECTORY, codalab_flag = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyF-AfIRKRCd"
      },
      "outputs": [],
      "source": [
        "##########################################################################################\n",
        "### Adapt from independent_pairs_to_predictions.py in the git of baseline or 3rd-place team\n",
        "##########################################################################################\n",
        "\n",
        "shutil.rmtree(CODALAB_SUBMISSION_DIRECTORY, ignore_errors = True)\n",
        "%cd /content/DFC2021-Track-MSD\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description = 'Helper script for combining DFC2021 prediction into submission format')\n",
        "parser.add_argument('--input_dir', type = str, required = True,\n",
        "                    help = 'The path to a directory containing the output of the `inference.py` script.')\n",
        "parser.add_argument('--output_dir', type = str, required = True,\n",
        "                    help = 'The path to output the consolidated predictions, should be different than `--input_dir`.')\n",
        "parser.add_argument('--overwrite', action = \"store_true\", help = 'Flag for overwriting `--output_dir` if that directory already exists.')\n",
        "parser.add_argument('--soft_assignment', action = \"store_true\",\n",
        "                    help = 'Flag for combining predictions using soft assignment. You can only use this if you ran the `inference.py` script with the `--save_soft` flag.')\n",
        "args = parser.parse_args(args=['--input_dir', CODALAB_PRED_DIRECTORY, '--output_dir', CODALAB_SUBMISSION_DIRECTORY])\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Starting to combine predictions at %s\" % (str(datetime.datetime.now())))\n",
        "\n",
        "    #-------------------\n",
        "    # Setup\n",
        "    #-------------------\n",
        "    assert os.path.exists(args.input_dir) and len(os.listdir(args.input_dir)) > 0\n",
        "\n",
        "    if os.path.isfile(args.output_dir):\n",
        "        print(\"A file was passed as `--output_dir`, please pass a directory!\")\n",
        "        return\n",
        "\n",
        "    if os.path.exists(args.output_dir) and len(os.listdir(args.output_dir)) > 0:\n",
        "        if args.overwrite:\n",
        "            print(\"WARNING! The output directory, %s, already exists, we might overwrite data in it!\" % (args.output_dir))\n",
        "        else:\n",
        "            print(\"The output directory, %s, already exists and isn't empty. We don't want to overwrite and existing results, exiting...\" % (args.output_dir))\n",
        "            return\n",
        "    else:\n",
        "        print(\"The output directory doesn't exist or is empty.\")\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    #-------------------\n",
        "    # Run for each pair of predictions that we find in `--input_dir`\n",
        "    #-------------------\n",
        "    idxs_2013 = [\n",
        "        fn.split(\"_\")[0]\n",
        "        for fn in os.listdir(args.input_dir)\n",
        "        if fn.endswith(\"predictions-2013.tif\")\n",
        "    ]\n",
        "\n",
        "    idxs_2017 = [\n",
        "        fn.split(\"_\")[0]\n",
        "        for fn in os.listdir(args.input_dir)\n",
        "        if fn.endswith(\"predictions-2017.tif\")\n",
        "    ]\n",
        "\n",
        "    assert len(idxs_2013) > 0, \"No matching files found in '%s'\" % (args.input_dir)\n",
        "    assert set(idxs_2013) == set(idxs_2017), \"Missing some predictions\"\n",
        "\n",
        "    for i, idx in enumerate(idxs_2013):\n",
        "        tic = time.time()\n",
        "\n",
        "        print(\"(%d/%d) Processing tile %s\" % (i, len(idxs_2013), idx), end = \" ... \")\n",
        "\n",
        "        if args.soft_assignment:\n",
        "            fn_2013 = os.path.join(args.input_dir, \"%s_predictions-soft-2013.tif\" % (idx))\n",
        "            fn_2017 = os.path.join(args.input_dir, \"%s_predictions-soft-2017.tif\" % (idx))\n",
        "        else:\n",
        "            fn_2013 = os.path.join(args.input_dir, \"%s_predictions-2013.tif\" % (idx))\n",
        "            fn_2017 = os.path.join(args.input_dir, \"%s_predictions-2017.tif\" % (idx))\n",
        "        output_fn = os.path.join(args.output_dir, \"%s_predictions.tif\" % (idx))\n",
        "\n",
        "        assert os.path.exists(fn_2013) and os.path.exists(fn_2017)\n",
        "\n",
        "        ## Load the independent predictions for both years\n",
        "        with rasterio.open(fn_2013) as f:\n",
        "            if args.soft_assignment:\n",
        "                t1 = np.rollaxis(f.read(), 0, 3)\n",
        "            else:\n",
        "                t1 = f.read(1)\n",
        "            input_profile = f.profile.copy() # save the metadata for writing output\n",
        "            \n",
        "        with rasterio.open(fn_2017) as f:\n",
        "            if args.soft_assignment:\n",
        "                t2 = np.rollaxis(f.read(), 0, 3)\n",
        "            else:\n",
        "                t2 = f.read(1)\n",
        "\n",
        "        t1_reduced = t1  # changed from the original git implementation\n",
        "        t2_reduced = t2  # changed from the original git implementation\n",
        "\n",
        "        ## Convert the two layers of predictions into the format expected by codalab\n",
        "        predictions = (t1_reduced * 4) + t2_reduced\n",
        "        predictions[predictions == 5] = 0\n",
        "        predictions[predictions == 10] = 0\n",
        "        predictions[predictions == 15] = 0\n",
        "        predictions = predictions.astype(np.uint8)\n",
        "\n",
        "        ## Write output as GeoTIFF\n",
        "        input_profile[\"count\"] = 1\n",
        "        with rasterio.open(output_fn, \"w\", **input_profile) as f:\n",
        "            f.write(predictions, 1)\n",
        "\n",
        "        print(\"finished in %0.4f seconds\" % (time.time() - tic))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQnKWWsPLC32"
      },
      "source": [
        "You can sign up to Codalab and submit the zip file after downloading it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7DfSMkcaUYK"
      },
      "outputs": [],
      "source": [
        "os.makedirs(CODALAB_SUBMISSION_ZIP_DIRECTORY, exist_ok = True)\n",
        "os.chdir(CODALAB_SUBMISSION_ZIP_DIRECTORY)\n",
        "if EVALUATE_ENSEMBLE_FLAG:\n",
        "    shutil.make_archive(OUTPUT_FILES_NAME + '_ENS_EVAL_M' + str(NUM_ENSEMBLE), format = 'zip', root_dir = CODALAB_SUBMISSION_DIRECTORY)\n",
        "else:\n",
        "    shutil.make_archive(OUTPUT_FILES_NAME, format = 'zip', root_dir = CODALAB_SUBMISSION_DIRECTORY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmXOYxGdLaaE"
      },
      "source": [
        "## Check the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBPkVabgK5WV"
      },
      "outputs": [],
      "source": [
        "codalab_pred_loader = sorted([file for file in os.listdir(CODALAB_SUBMISSION_DIRECTORY) if file.endswith('.tif')])\n",
        "\n",
        "for i, file in enumerate(tqdm(codalab_pred_loader)):\n",
        "    ds = gdal.Open(os.path.join(CODALAB_SUBMISSION_DIRECTORY, file), gdal.GA_ReadOnly)\n",
        "    codalab_pred_np = np.array([ds.GetRasterBand(i + 1).ReadAsArray() for i in range(ds.RasterCount)])\n",
        "    if max(codalab_pred_np[0].flatten()) > 14:\n",
        "        print(f'\\n\\n{file} is wrong!')\n",
        "        print(f'\\nsize: ({ds.RasterXSize}, {ds.RasterYSize})\\n')\n",
        "        print(pd.Series(codalab_pred_np[0].flatten()).value_counts())\n",
        "        break\n",
        "    if i == len(codalab_pred_loader) - 1:\n",
        "        print('\\n\\nThe format looks OK')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}