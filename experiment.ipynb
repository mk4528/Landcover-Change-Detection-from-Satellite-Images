{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de6765b-f3d3-4554-9a45-ed706b3d83e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 15:51:04.314052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 15:51:04.509829: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-07 15:51:04.591720: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-07 15:51:05.539973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hegelim/miniconda3/envs/tensorflow/lib/\n",
      "2022-11-07 15:51:05.540126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hegelim/miniconda3/envs/tensorflow/lib/\n",
      "2022-11-07 15:51:05.540136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7612663-bb55-4a59-8a5e-56e9f196f555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 21, 21, ..., 41, 41, 41],\n",
       "       [21, 21, 21, ..., 41, 41, 41],\n",
       "       [21, 21, 21, ..., 41, 41, 41],\n",
       "       ...,\n",
       "       [41, 41, 41, ..., 41, 41, 41],\n",
       "       [41, 41, 41, ..., 41, 41, 41],\n",
       "       [41, 41, 41, ..., 41, 41, 41]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import io\n",
    "\n",
    "nlcd_test = io.imread(\"NAIP_NLCD_train_2013/NLCD/img/496_1.png\")\n",
    "nlcd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a1af40-ce46-4e59-9841-120fe72b938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17f3251-0484-4f99-a7c4-cab47e0106f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlcd_preprocess(img):\n",
    "    # map from orignal ints to ints within 0 to 5\n",
    "    remapper = lambda x: utils.nlcd_2_int_mapping[x]\n",
    "    return np.vectorize(remapper)(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4837d16-ca49-4170-a101-4c509876427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 1, 1, 1],\n",
       "       [2, 2, 2, ..., 1, 1, 1],\n",
       "       [2, 2, 2, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlcd_test = nlcd_preprocess(nlcd_test)\n",
    "nlcd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ab58ea-c474-4f58-9342-e2b707abd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.CategoryEncoding(num_tokens=5, output_mode=\"one_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eacb052f-fcfb-4795-8c08-094332e776d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = keras.utils.to_categorical(nlcd_test, num_classes=5)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fce178-fcb5-4d81-ad7c-998c6491eecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlcd_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6321752-3e3f-4233-baf9-47517d0a4f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74fa5e4-2964-4c74-acc8-d19a158dbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [11, 22, 23],\n",
    "    [24, 31, 41],\n",
    "    [42, 43, 52],\n",
    "    [71, 81, 82]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c26eb815-e04a-41e6-a56d-e487c5ca6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9ab2f13-f9b8-4ba6-b2db-e789883d203f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.98, 0.2 , 0.  , 0.  ],\n",
       "        [0.  , 0.39, 0.49, 0.12],\n",
       "        [0.01, 0.13, 0.22, 0.64]],\n",
       "\n",
       "       [[0.  , 0.03, 0.07, 0.9 ],\n",
       "        [0.05, 0.13, 0.43, 0.4 ],\n",
       "        [0.  , 0.93, 0.05, 0.  ]],\n",
       "\n",
       "       [[0.  , 0.95, 0.04, 0.  ],\n",
       "        [0.  , 0.92, 0.07, 0.  ],\n",
       "        [0.  , 0.58, 0.38, 0.04]],\n",
       "\n",
       "       [[0.01, 0.23, 0.54, 0.22],\n",
       "        [0.  , 0.12, 0.83, 0.03],\n",
       "        [0.  , 0.05, 0.92, 0.01]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.vectorize(lambda x: softmap[x], signature='()->(n)')(a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de8f39f5-9df2-479a-accf-fe377962efed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 3, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.append(c)\n",
    "b = np.array(b)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74262aef-a244-4322-a096-87c8269ae0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [1, 3],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1, 2, 3])\n",
    "\n",
    "mapp = {1: np.array([2, 3]), 2: np.array([1, 3]), 3: np.array([1, 2])}\n",
    "\n",
    "np.vectorize(lambda x: mapp[x], signature='()->(n)')(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee1621a2-c57a-4c03-82fe-05bdb941d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmap = {\n",
    "    11: np.array([0.98, 0.2, 0.0, 0.0]),\n",
    "    22: np.array([0.0, 0.39, 0.49, 0.12]),\n",
    "    23: np.array([0.01, 0.13, 0.22, 0.64]),\n",
    "    24: np.array([0, 0.03, 0.07, 0.9]),\n",
    "    31: np.array([0.05, 0.13, 0.43, 0.4]),\n",
    "    41: np.array([0, 0.93, 0.05, 0]),\n",
    "    42: np.array([0, 0.95, 0.04, 0]),\n",
    "    43: np.array([0, 0.92, 0.07, 0]),\n",
    "    52: np.array([0, 0.58, 0.38, 0.04]),\n",
    "    71: np.array([0.01, 0.23, 0.54, 0.22]),\n",
    "    81: np.array([0, 0.12, 0.83, 0.03]),\n",
    "    82: np.array([0, 0.05, 0.92, 0.01]),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
